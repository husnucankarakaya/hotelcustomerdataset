# -*- coding: utf-8 -*-
"""ChatGPT_HotelCustomers.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NjIkDZq4hCneprcgKtSGhD055sLZxq_q
"""

# Google Drive'ı bağlamak için
from google.colab import drive
drive.mount('/content/drive')

# Pandas ile Excel dosyasını okumak
import pandas as pd

# Dosya yolunu belirtin (Drive içindeki dosya yolunuza göre düzenleyin)
file_path = '/content/drive/My Drive/HotelCustomersDataset.xlsx'

# Veri setini oku
df = pd.read_excel(file_path)

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10,6))
sns.histplot(df['Age'], bins=30, kde=True, color='skyblue')
plt.title('Müşteri Yaş Dağılımı')
plt.xlabel('Yaş')
plt.ylabel('Müşteri Sayısı')
plt.grid(True)
plt.show()

plt.figure(figsize=(10,6))
top_nationalities = df['Nationality'].value_counts().head(10)
sns.barplot(x=top_nationalities.values, y=top_nationalities.index, palette='viridis')
plt.title('En Çok Gelen İlk 10 Ülke')
plt.xlabel('Müşteri Sayısı')
plt.ylabel('Ülke')
plt.grid(True, axis='x')
plt.show()

plt.figure(figsize=(6,6))
canceled_counts = canceled[[0, 1]] # Select counts for 0 and 1
labels = ['İptal Edilmemiş', 'İptal Edilmiş']
plt.pie(canceled_counts, labels=labels, autopct='%1.1f%%', colors=['lightgreen', 'salmon'], startangle=90)
plt.title('İptal Edilen vs Edilmeyen Rezervasyonlar')
plt.axis('equal')
plt.show()

plt.figure(figsize=(10,6))
sns.histplot(df['RoomNights'], bins=30, kde=True, color='orange')
plt.title('Müşteri Başına Oda Gecesi Sayısı Dağılımı')
plt.xlabel('RoomNights')
plt.ylabel('Müşteri Sayısı')
plt.grid(True)
plt.show()

plt.figure(figsize=(10,6))
sns.boxplot(x=df['LodgingRevenue'], color='teal')
plt.title('Konaklama Geliri Dağılımı (Boxplot)')
plt.xlabel('Lodging Revenue')
plt.grid(True)
plt.show()

plt.figure(figsize=(10,6))
sns.histplot(df['BookingsCheckedIn'], bins=20, color='purple', kde=True)
plt.title('Check-in Sayısı Dağılımı')
plt.xlabel('Check-in Sayısı')
plt.ylabel('Müşteri Sayısı')
plt.grid(True)
plt.show()

plt.figure(figsize=(10,6))
segment_counts = df['MarketSegment'].value_counts()
sns.barplot(x=segment_counts.index, y=segment_counts.values, palette='Set2')
plt.title('Pazar Segmentleri Dağılımı')
plt.xlabel('Pazar Segmenti')
plt.ylabel('Müşteri Sayısı')
plt.xticks(rotation=45)
plt.grid(True, axis='y')
plt.show()

plt.figure(figsize=(10,6))
channel_counts = df['DistributionChannel'].value_counts()
sns.barplot(x=channel_counts.index, y=channel_counts.values, palette='Set3')
plt.title('Rezervasyon Kanal Dağılımı')
plt.xlabel('Kanal')
plt.ylabel('Müşteri Sayısı')
plt.xticks(rotation=45)
plt.grid(True, axis='y')
plt.show()

plt.figure(figsize=(6,6))
quiet_room = df['SRQuietRoom'].value_counts()
labels = ['İstememiş', 'İstemiş']
plt.pie(quiet_room, labels=labels, autopct='%1.1f%%', colors=['lightgrey', 'lightblue'])
plt.title('Sessiz Oda Talebi')
plt.axis('equal')
plt.show()

df.info()

df.describe(include='all').T

import missingno as msno

# Eksik değer sayısı
missing = df.isnull().sum()
missing[missing > 0]

# Görsel olarak eksik değer gösterimi
msno.matrix(df, figsize=(12,6))
plt.title("Eksik Değer Görselleştirmesi")
plt.show()

plt.figure(figsize=(14,10))
correlation_matrix = df.corr(numeric_only=True)
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap="coolwarm", square=True)
plt.title('Değişkenler Arası Korelasyon Matrisi')
plt.show()

plt.figure(figsize=(8,5))
sns.boxplot(x=df['Age'], color='salmon')
plt.title('Age Değişkeninde Aykırı Değerler')
plt.xlabel('Yaş')
plt.grid(True)
plt.show()

plt.figure(figsize=(8,6))
sns.scatterplot(data=df, x='Age', y='LodgingRevenue', alpha=0.5)
plt.title('Yaş vs Konaklama Geliri')
plt.xlabel('Yaş')
plt.ylabel('Konaklama Geliri')
plt.grid(True)
plt.show()

plt.figure(figsize=(10,6))
sns.barplot(data=df, x='MarketSegment', y='LodgingRevenue', estimator='mean', palette='pastel')
plt.title('Pazar Segmentlerine Göre Ortalama Konaklama Geliri')
plt.xlabel('Pazar Segmenti')
plt.ylabel('Ortalama Konaklama Geliri')
plt.xticks(rotation=45)
plt.grid(True, axis='y')
plt.show()

plt.figure(figsize=(8,6))
sns.boxplot(data=df, x='SRQuietRoom', y='LodgingRevenue', palette='coolwarm')
plt.title('Sessiz Oda Talebine Göre Gelir Dağılımı')
plt.xlabel('Sessiz Oda Talebi (0: Hayır, 1: Evet)')
plt.ylabel('Konaklama Geliri')
plt.grid(True)
plt.show()

plt.figure(figsize=(10,6))
sns.scatterplot(data=df, x='DaysSinceFirstStay', y='DaysSinceLastStay', hue='BookingsCheckedIn', palette='viridis')
plt.title('Sadakat Analizi: İlk ve Son Kalış Arası')
plt.xlabel('İlk Kalıştan Bu Yana Gün')
plt.ylabel('Son Kalıştan Bu Yana Gün')
plt.grid(True)
plt.show()

sample_df = df[['Age', 'LodgingRevenue', 'RoomNights', 'BookingsCheckedIn']].dropna().sample(500)

sns.pairplot(sample_df)
plt.suptitle('Numerik Değişkenler Arası İlişki', y=1.02)
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler

# Özellik seçimi ve hedef
features = ['Age', 'AverageLeadTime', 'RoomNights', 'PersonsNights', 'DaysSinceCreation']
target = 'BookingsCanceled'

# Eksik veri temizliği
df_model = df[features + [target]].dropna()

# Özellikleri ve hedefi ayır
X = df_model[features]
y = df_model[target]

# Standartlaştırma
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Veri setini ayır
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

import seaborn as sns
from sklearn.metrics import ConfusionMatrixDisplay

# Confusion matrix
ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap="Blues")
plt.title("Lojistik Regresyon: Confusion Matrix")
plt.show()

# Sınıflandırma raporu
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Özellik ve hedef
features = ['Age', 'RoomNights', 'AverageLeadTime', 'PersonsNights', 'DaysSinceCreation']
target = 'LodgingRevenue'

# Veri temizleme
df_reg = df[features + [target]].dropna()

X = df_reg[features]
y = df_reg[target]

# Eğitim-test ayrımı
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred = rf_model.predict(X_test)

# Metrikler
mae = mean_absolute_error(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred) ** 0.5
r2 = r2_score(y_test, y_pred)

print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"R² Score: {r2:.2f}")

plt.figure(figsize=(8,6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)
plt.xlabel("Gerçek Gelir")
plt.ylabel("Tahmin Edilen Gelir")
plt.title("Random Forest: Gerçek vs Tahmin Gelir")
plt.grid(True)
plt.show()

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

cluster_features = ['Age', 'RoomNights', 'AverageLeadTime', 'PersonsNights', 'LodgingRevenue']
df_cluster = df[cluster_features].dropna()

# Normalizasyon
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df_cluster)

wcss = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

plt.figure(figsize=(8,5))
plt.plot(range(1,11), wcss, marker='o')
plt.title('Elbow Yöntemi - Optimum Küme Sayısı')
plt.xlabel('Küme Sayısı')
plt.ylabel('WCSS')
plt.grid(True)
plt.show()

kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# Küme numaralarını ekle
df_cluster['Cluster'] = clusters

# PCA ile 2 boyuta indirgeme
pca = PCA(n_components=2)
components = pca.fit_transform(X_scaled)
df_cluster['PCA1'] = components[:,0]
df_cluster['PCA2'] = components[:,1]

# Görselleştirme
plt.figure(figsize=(8,6))
sns.scatterplot(data=df_cluster, x='PCA1', y='PCA2', hue='Cluster', palette='Set1')
plt.title('K-Means Kümeleme Sonucu (PCA ile Görselleştirme)')
plt.grid(True)
plt.show()

from sklearn.neighbors import NearestNeighbors

# Özellikler (müşterilerin davranışsal özellikleri)
knn_features = ['Age', 'RoomNights', 'PersonsNights', 'LodgingRevenue', 'BookingsCheckedIn']
df_knn = df[knn_features].dropna()

# Normalizasyon
scaler = StandardScaler()
X_knn = scaler.fit_transform(df_knn)

knn = NearestNeighbors(n_neighbors=6, metric='euclidean')  # kendisi + 5 komşu
knn.fit(X_knn)

# 100. müşteri
distances, indices = knn.kneighbors([X_knn[100]])

# Benzer müşterilerin indeksleri
print("Seçilen müşteri (100. sıra):")
print(df_knn.iloc[100])
print("\nEn benzer müşteriler:")
print(df_knn.iloc[indices[0][1:]])  # ilk müşteri kendisi olduğu için atlıyoruz

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_knn)

plt.figure(figsize=(8,6))
plt.scatter(X_pca[:,0], X_pca[:,1], alpha=0.4, label="Tüm Müşteriler")
plt.scatter(X_pca[100,0], X_pca[100,1], color='red', label='Seçilen Müşteri', s=100)

for i in indices[0][1:]:
    plt.scatter(X_pca[i,0], X_pca[i,1], color='green', label='Benzer Müşteri', s=80)

plt.legend()
plt.title("KNN ile Benzer Müşteri Görselleştirmesi (PCA)")
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt

# 1. Varsayılan bugünün tarihi
today = pd.to_datetime("2020-01-01")

# 2. Müşteri oluşturulma tarihini hesapla
df['CreationDate'] = today - pd.to_timedelta(df['DaysSinceCreation'], unit='D')

# 3. Zaman serisini oluştur (aylık bazda toplam gelir)
df_ts = df[['CreationDate', 'LodgingRevenue']].dropna()
df_ts = df_ts.set_index('CreationDate')
monthly_revenue = df_ts.resample('M').sum()

# 4. Eksik değerleri ileriye doğru doldur
monthly_revenue = monthly_revenue.asfreq('M').fillna(method='ffill')

# 5. Görselleştirme
plt.figure(figsize=(10, 6))
monthly_revenue.plot()
plt.title("Aylık Konaklama Geliri (Simüle Edilmiş Zaman Serisi)")
plt.xlabel("Tarih")
plt.ylabel("Toplam Konaklama Geliri")
plt.grid(True)
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import classification_report

# Örnek hedef: Ücretsiz iptal durumu
X = df[['Age', 'RoomNights', 'AverageLeadTime', 'PersonsNights']].dropna()
y = df.loc[X.index, 'BookingsCanceled'].astype(int)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear']
}

logreg = LogisticRegression()
grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

print("En iyi parametreler:", grid_search.best_params_)
print("\nSınıflandırma Raporu:")
print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt

# GridSearch sonuçlarını DataFrame'e çevir
results = pd.DataFrame(grid_search.cv_results_)

# C parametresine göre accuracy skoru (l1 ve l2 için ayrı ayrı)
plt.figure(figsize=(8,5))
sns.lineplot(data=results, x="param_C", y="mean_test_score", hue="param_penalty", marker="o")
plt.title("Lojistik Regresyon: C ve Penalty'ye Göre Doğruluk")
plt.xlabel("C Değeri")
plt.ylabel("Ortalama Doğruluk (CV)")
plt.grid(True)
plt.show()

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

X = df[['Age', 'RoomNights', 'AverageLeadTime', 'PersonsNights', 'DaysSinceCreation']].dropna()
y = df.loc[X.index, 'LodgingRevenue']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5]
}

rf = RandomForestRegressor(random_state=42)
grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='r2', n_jobs=-1, verbose=1)
grid_search.fit(X_train, y_train)

best_rf = grid_search.best_estimator_
print("En iyi parametreler:", grid_search.best_params_)
print("R2:", r2_score(y_test, best_rf.predict(X_test)))

# GridSearch sonuçlarını al
results_rf = pd.DataFrame(grid_search.cv_results_)

# n_estimators ve max_depth'e göre R2 skorlarını çiz
pivot_rf = results_rf.pivot_table(values="mean_test_score",
                                  index="param_n_estimators",
                                  columns="param_max_depth")

plt.figure(figsize=(8,6))
sns.heatmap(pivot_rf, annot=True, fmt=".3f", cmap="YlGnBu")
plt.title("Random Forest: n_estimators & max_depth'e Göre R2 Skoru")
plt.xlabel("max_depth")
plt.ylabel("n_estimators")
plt.show()

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

X = df[['Age', 'RoomNights', 'AverageLeadTime', 'PersonsNights']].dropna()
X_scaled = StandardScaler().fit_transform(X)

inertia = []
k_range = range(2, 11)

for k in k_range:
    model = KMeans(n_clusters=k, random_state=42)
    model.fit(X_scaled)
    inertia.append(model.inertia_)

plt.figure(figsize=(8,5))
plt.plot(k_range, inertia, marker='o')
plt.title("Elbow Method: En İyi Küme Sayısı")
plt.xlabel("Küme Sayısı (k)")
plt.ylabel("Inertia (WSS)")
plt.grid(True)
plt.show()

from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import pairwise_distances

X = df[['Age', 'RoomNights', 'PersonsNights', 'LodgingRevenue']].dropna()
X_scaled = StandardScaler().fit_transform(X)

# Farklı komşu sayıları için toplam mesafeyi ölç
scores = []
for k in range(2, 11):
    model = NearestNeighbors(n_neighbors=k)
    model.fit(X_scaled)
    distances, _ = model.kneighbors(X_scaled)
    avg_distance = distances[:, 1:].mean()  # kendisi hariç
    scores.append(avg_distance)

plt.figure(figsize=(8,5))
plt.plot(range(2, 11), scores, marker='o')
plt.title("KNN: Komşu Sayısına Göre Ortalama Mesafe")
plt.xlabel("Komşu Sayısı (k)")
plt.ylabel("Ortalama Mesafe")
plt.grid(True)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.arima.model import ARIMA
import itertools
import warnings
warnings.filterwarnings("ignore")

# Zaman serisi oluştur
df_sorted = df[['DaysSinceCreation', 'LodgingRevenue']].dropna().sort_values('DaysSinceCreation')
df_sorted = df_sorted.groupby('DaysSinceCreation').sum()

# Parametre aralıkları
p_values = range(0, 4)
d_values = range(0, 2)
q_values = range(0, 4)

best_score, best_order = float("inf"), None
aic_scores = []

# Grid search
for order in itertools.product(p_values, d_values, q_values):
    try:
        model = ARIMA(df_sorted['LodgingRevenue'], order=order)
        results = model.fit()
        aic = results.aic
        aic_scores.append((order, aic))
        if aic < best_score:
            best_score, best_order = aic, order
    except:
        continue

# Sonuçları DataFrame'e çevir
aic_df = pd.DataFrame(aic_scores, columns=["order", "AIC"]).sort_values("AIC")

# Convert the tuple 'order' column to strings for plotting
aic_df['order_str'] = aic_df['order'].apply(lambda x: str(x))

# Görselleştir
plt.figure(figsize=(10,6))
# Use the new 'order_str' column for the x-axis
sns.barplot(data=aic_df.head(10), x="order_str", y="AIC", palette="mako")
plt.title("ARIMA: En İyi 10 Parametre Kombinasyonu (AIC Skoruna Göre)")
plt.ylabel("AIC Skoru (Düşük Daha İyi)")
plt.xlabel("ARIMA(p,d,q)")
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

print("En iyi ARIMA parametresi:", best_order)